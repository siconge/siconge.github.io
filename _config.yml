# Site
repository: siconge/siconge.github.io
favicon: images/favicon.svg

# Content configuration version
version: 2

# Personal info
name: Sicong E
title: Data Engineer
email: esicong@gmail.com
# email_title: Email (Email title override)
phone: +1(213)400-2486
# phone_title: Phone (Phone title override)
website: https://siconge.github.io
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: jekyllrb
github_username:  siconge
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
# instagram_username: jekyll
linkedin_username: siconge
# xing_username: jekyll
# pinterest_username: jekyll
# youtube_username: jekyll
# orcid_username: 0000-0000-0000-0000
# googlescholar_username: D847cGsAAAAJ

# Additional icon links
# additional_links:
# - title: Link name
#   icon: Font Awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  Aspiring Data Engineer with a robust background in Building Information Modeling (BIM) data engineering, specializing in <mark>data pipeline development</mark>, 
  <mark>ETL automation</mark>, and <mark>cloud data services</mark>. Proficient in <mark>Python</mark>, <mark>SQL</mark>, <mark>AWS</mark>, 
  <mark>Airflow</mark>, and <mark>Spark</mark>, with hands-on experience in <mark>big data technologies</mark>, <mark>data warehousing</mark>, and <mark>API integrations</mark>. 
  Demonstrated ability to manage complex projects and lead cross-functional teams to deliver impactful solutions. 
  Licensed Architect with over a decade of experience, now leveraging architectural insights to enhance data engineering projects. 
  Passionate about continuous learning and contributing to innovative data-driven solutions.

content:

  - title: Work History
    layout: list
    content:
      - layout: top-left
        title: NBBJ
        sub_title: Project Architect | BIM Data Engineer
        caption: Sep 2021 - Dec 2023
        link: www.nbbj.com
        quote: >
          Global architecture and design firm integrating data-driven methodologies for enhanced decision-making
        #   Short description of the company (optional)
        description: | # this will include new lines to allow paragraphs
          - Developed a comprehensive data pipeline using Apache Airflow and AWS services (S3, Glue, Athena, Redshift) 
          to manage BIM data for 6,600 curtain wall units of the 207,700 m² Tencent Global Headquarters
          - Automated ETL processes with Autodesk Platform Services API for real-time data extraction, Pandas for pre-processing, 
          AWS Python SDK for ingestion to Amazon S3, and AWS Glue and PySpark for further transformation and integration, 
          reducing manual workload by over 75% and improving efficiency by over 50%
          - Facilitated informed and timely decision-making by providing accessible data and insights using Athena and Redshift for design decisions, 
          construction modifications, cost estimation, and regulatory compliance
          - Led a team of 15 architects across 3 global studios, overseeing client and consultant coordination, and technical solutions, 
          ensuring seamless project execution and stakeholder satisfaction

      - layout: top-left
        title: 5+design
        sub_title: Project Designer | BIM Manager
        caption: Jun 2011 - Sep 2021
        link: www.5plusdesign.com/
        quote: >
          Architecture firm specializing in retail, mixed-use, residential, and large-scale urban planning
        #   Short description of the company (optional)
        description: | # this will include new lines to allow paragraphs
          - Leveraged BIM software to streamline design modeling and documentation for 10+ global projects, increasing project planning and delivery efficiency by 33%
          - Conducted data analysis on data-driven facade modules to support parametric design feasibility studies
          
  - title: Education
    layout: list
    content:
      - layout: top-left
        title: MIT xPRO
        sub_title: Prof. Certificate in Data Engineering
        caption: Aug 2023 - Mar 2024
        link: xpro.mit.edu
        # quote: >
          # Short institution or course description (optional)
        description: | # this will include new lines to allow paragraphs
          This program equipped me with the skills to advance my career in data engineering. Key learning outcomes include:
          
          - **Data Processing, Analysis and Visualization**: Proficient in Python and multiple libraries, including 
          NumPy, Pandas, Matplotlib, PySpark, SQLAlchemy, PyMongo, Scikit-learn, SciPy, DASK, NLTK, Graphviz, and Paho.
          - **Database Design and Management**: Proficient in SQL; wrote complex database queries; conducted database schema design (data modeling); 
          involved common RDBMS and NoSQL databases; applied regular expressions.
          - **Database Containerization**: Used Docker to create and manipulate images and containers; 
          performed change data capture (CDC) in different types of databases including MongoDB, Cassandra, Redis, and Firebase.
          - **ETL Processes and Data Pipelines**: Performed extract, transform, and load (ETL) operations using Python; 
          created ETL pipelines and orchestrated workflows using Apache Airflow.
          - **Big Data Handling**: Processed big data using Spark and Hadoop; ran parallel operations using DASK; 
          handled real-time streaming data using Mosquitto, ThingsBoard, and Kafka.
          - **Statistics Basics**: Identified key concepts in statistics, including various types of probability distributions, Central Limit Theorem, and correlation.
          - **AI/ML Algorithms**: Built a prediction modeling using linear regression; 
          implemented foundational ML algorithms, including gradient descent for error reduction, classification with Naïve Bayes theorems, 
          clustering (k-means), reinforcement learning (Q-matrix, Bellman equation), and deep neural networks.
          - **Software Engineering and Network Basics**: Grasped commonly used command line commands; 
          identified key concepts of Java, asynchronous event-driven programming, and HTTP and client–server architecture; 
          created applications using Flask web server and Jinja templating language.
          
      - layout: top-left
        title: University of Southern California (USC)
        sub_title: Master of Architecture
        caption: Sep 2009 - May 2011
        link: www.usc.edu
        # quote: >
          # Short institution or course description (optional)
        description: | # this will include new lines to allow paragraphs
          USC provided a comprehensive education in architecture, emphasizing data-driven aspects. 
          This honed my ability to manage and analyze complex datasets in building design and construction. Key learning outcomes relevant to data engineering include:
          
          - **BIM Data Management**: Proficient in Building Information Modeling (BIM) using Revit, focusing on managing and analyzing large datasets generated by BIM processes.
          - **Data Analysis in Architecture**: Skilled in extracting and manipulating BIM data to enhance project decision-making and optimize design and construction processes.
          - **Revit Proficiency**: Expertise in using Revit for architectural design and data extraction, contributing to efficient project workflows and accurate data management.

          This unique combination of skills positions me well for roles in data engineering, 
          where technical proficiency and the ability to manage and interpret large datasets are crucial.
          
  - title: Projects # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: top-middle
        # border: weak  # Value of `weak` will display a weak border below this item.
                      # Any other value (or no value) means no border will be displayed
        title: Tencent Headquarters BIM Data Pipeline Using Revit, Apache Airflow, and AWS Services
        link: github.com/siconge/Tencent-HQ-BIM-Data-Pipeline-with-AWS
        # link_text: Link Text
        # additional_links:
        #   - title:  Github repo for project
        #     icon: fab fa-github fa-2x
        #     url: https://github.com/siconge/Tencent-HQ-BIM-Data-Pipeline-with-AWS
        # border: weak  # Value of `weak` will display a weak border below this item.
                      # Any other value (or no value) means no border will be displayed
        # quote: >
        #   Short overview of the project (optional)
        description: | # this will include new lines to allow paragraphs
          This project delivers a robust data pipeline solution designed to efficiently handle BIM (Building Information Modeling) data 
          from the Revit model of Tencent Global Headquarters in Shenzhen. As the Lead Project Architect and BIM Data Engineer, 
          I oversaw the design and construction phases, ensuring seamless integration and data management.
          
          This data pipeline employs a comprehensive ETL (Extract, Transform, Load) process to move BIM data from Autodesk Revit into cloud storage for processing and analytics. 
          The pipeline leverages tools and services such as Apache Airflow, Amazon S3, AWS Glue, Amazon Athena, and Amazon Redshift.
          
          Specifically designed to serve the design team, technical consultants, and Tencent clients, this pipeline supports informed decision-making, 
          construction detail modifications, cost estimation, and compliance with local regulations such as energy consumption, window-to-wall ratio, and fire protection standards. 
          The focus on the unitized curtain wall system demonstrates how data-driven processes assist in fine-tuning design and construction details 
          to meet various code requirements while maintaining the overall design intent. This approach ensures precise tracking and management of architectural elements, 
          enhancing overall project outcomes.
          
          <a href="https://siconge.github.io/Tencent-HQ-BIM-Data-Pipeline-with-AWS">Continue reading >></a>

      
      - layout: top-middle
        title: "Real-time Transit Data Pipeline: ETL and CDC from MBTA to MySQL and MongoDB"
        link: github.com/siconge/Real-time-Transit-Data-Pipeline-MBTA-ETL-CDC
        # additional_links:
        #   - title: Github repo for project
        #     icon: fab fa-github fa-2x
        #     url: https://github.com/siconge/Real-time-Transit-Data-Pipeline-MBTA-ETL-CDC
        description: | # this will include new lines to allow paragraphs
          This project presents a comprehensive and integrated real-world data engineering pipeline that leverages real-time transit data from 
          the Massachusetts Bay Transportation Authority (MBTA).
          
          The pipeline demonstrates the use of Extract, Transform, Load (ETL) and Change Data Capture (CDC) processes to ensure real-time data ingestion and storage, 
          as well as data synchronization across storage systems for efficient data replication and consistency. Utilizing a variety of data engineering tools and technologies, 
          including Docker, Apache Airflow, MySQL, MongoDB, and Python MySQL Replication, the pipeline supports real-time data availability, event-driven architectures, 
          and disaster recovery. This makes it an exemplary model for handling dynamic data in a production-like environment.
          
          In addition to real-time data handling, the pipeline also facilitates historical data analysis and visualization. 
          This enables time-series analysis and trend detection to provide insights into transit patterns, informing decision-making and optimizing transit operations.
          
          <a href="https://siconge.github.io/Real-time-Transit-Data-Pipeline-MBTA-ETL-CDC">Continue reading >></a>

      - layout: top-middle
        title: ETL Processing and Time Series Analysis of MRTS Dataset
        link: github.com/siconge/MRTS-ETL-Time-Series-Analysis
        # additional_links:
        #   - title: Github repo for project
        #     icon: fab fa-github fa-2x
        #     url: https://github.com/siconge/MRTS-ETL-Time-Series-Analysis
        description: | # this will include new lines to allow paragraphs
          The Monthly Retail Trade Survey (MRTS) is conducted by the U.S. Census Bureau to gather data from retail businesses, 
          providing insights into the retail sector's performance. This data covers various aspects of retail, including sales and inventories. 
          
          This project has two primary goals: to perform ETL (Extract, Transform, Load) processing on the MRTS dataset using Python and powerful data transformation libraries 
          like Pandas and SQLAlchemy, and to apply key time series analysis techniques, including trend analysis, percentage changes, and rolling time windows, to analyze the data of target businesses. 
          The process involves using MySQL for data retrieval and Python for detailed data manipulation and visualization.
          
          <a href="https://siconge.github.io/MRTS-ETL-Time-Series-Analysis">Continue reading >></a>
          
  - title: Skills
    layout: text
    content: | # this will include new lines to allow paragraphs
      - **Programming Languages**: Python (Pandas, Numpy, Matplotlib, PySpark, SQLAlchemy, Scikit-learn)
      - **Data Storage & Processing**: SQL (MySQL), AWS, Airflow, Spark, Docker, Azure, Kafka, Linux CLI
      - **Data Engineering & Analytics**: Data Pipeline, ETL, Data Modeling, Analysis, Visualization, Debugging, Git, CDC, Statistics, Machine Learning
      - **Languages**: English, Madarin, Japanese
      
  - title: Certifications
    layout: text
    content: |
      - **AWS Certified Solutions Architect - Associate**
      - **California Licensed Architect**

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# Use this is you are hosting your resume yourself
# theme: jekyll-theme-minimal
# Use this if you are hosting your resume on GitHub
remote_theme: sproogen/modern-resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
